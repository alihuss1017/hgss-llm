{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "github_token = userdata.get('GITHUB_TOKEN')\n",
        "!git clone https://alihuss1017:{github_token}@github.com/alihuss1017/hgss-llm.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gC1T_uWV2BS0",
        "outputId": "e2ac482a-d6fa-401c-b060-ee7b6bdf79e0"
      },
      "id": "gC1T_uWV2BS0",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'hgss-llm'...\n",
            "remote: Enumerating objects: 135, done.\u001b[K\n",
            "remote: Counting objects: 100% (87/87), done.\u001b[K\n",
            "remote: Compressing objects: 100% (62/62), done.\u001b[K\n",
            "remote: Total 135 (delta 26), reused 82 (delta 25), pack-reused 48 (from 1)\u001b[K\n",
            "Receiving objects: 100% (135/135), 508.52 KiB | 15.89 MiB/s, done.\n",
            "Resolving deltas: 100% (35/35), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd hgss-llm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMQy5OmA2u3t",
        "outputId": "35cabf9a-6cb9-49c3-b574-7b73da3c8118"
      },
      "id": "lMQy5OmA2u3t",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/hgss-llm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git checkout -b RAG-pipeline origin/RAG-pipeline"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3mVxFOj2qqN",
        "outputId": "2111b71d-37be-4e1d-9c57-2bf74a6f20d2"
      },
      "id": "o3mVxFOj2qqN",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Branch 'RAG-pipeline' set up to track remote branch 'RAG-pipeline' from 'origin'.\n",
            "Switched to a new branch 'RAG-pipeline'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RDqLuhZ0dh9l",
      "metadata": {
        "id": "RDqLuhZ0dh9l"
      },
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ouy6ori5jlMs",
      "metadata": {
        "id": "Ouy6ori5jlMs"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "doc_embeddings = embedder.encode(documents, convert_to_numpy = True)\n",
        "\n",
        "index = faiss.IndexFlatL2(doc_embeddings.shape[1])\n",
        "index.add(doc_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Sht936l7j7RZ",
      "metadata": {
        "id": "Sht936l7j7RZ"
      },
      "outputs": [],
      "source": [
        "def retrieve_relevant_context(query, top_k = 1):\n",
        "  query_embedding = embedder.encode([query], convert_to_numpy = True)\n",
        "  D, I = index.search(query_embedding, top_k)\n",
        "  return [documents[i] for i in I[0]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KLcqg3uJk5nM",
      "metadata": {
        "id": "KLcqg3uJk5nM"
      },
      "outputs": [],
      "source": [
        "from transformers import GPTNeoXForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "model = GPTNeoXForCausalLM.from_pretrained(\n",
        "  \"EleutherAI/pythia-160m-deduped\",\n",
        "  revision=\"step3000\",\n",
        "  cache_dir=\"./pythia-160m-deduped/step3000\",\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "  \"EleutherAI/pythia-160m-deduped\",\n",
        "  revision=\"step3000\",\n",
        "  cache_dir=\"./pythia-160m-deduped/step3000\",\n",
        ")\n",
        "\n",
        "def generate_answer(query):\n",
        "  context = retrieve_relevant_context(query)\n",
        "  prompt = (\n",
        "      f'Context:\\n{chr(10).join(context)}\\n\\n'\n",
        "      f'Question: {query}\\nAnswer:'\n",
        "  )\n",
        "\n",
        "  inputs = tokenizer(prompt, return_tensors = 'pt', truncation = True)\n",
        "  outputs = model.generate(**inputs, max_new_tokens = 100)\n",
        "  return tokenizer.decode(outputs[0], skip_special_tokens = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XJYALCYYlf7p",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJYALCYYlf7p",
        "outputId": "da640c0c-b049-40a1-f8bd-1a4d38c26926"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Context:\n",
            "TM01:Focus Punch is a Fighting-type Physical move.It has 150 power, 100 accuracy, and 20 PP. It is found/located at Cianwood City Gym.Effect: A powerful loyalty attack. The user flinches if hit.\n",
            "\n",
            "Question: Based on the context, what is Focus Punch's accuracy value?\n",
            "Answer:\n",
            "\n",
            "Focus Punch's accuracy value is the ability to control the movement of the target.\n",
            "\n",
            "Question: How does Focus Punch's accuracy value affect the movement of the target?\n",
            "Answer:\n",
            "\n",
            "Focus Punch's accuracy value is the ability to control the movement of the target.\n",
            "\n",
            "Question: How does Focus Punch's accuracy value affect the movement of the target?\n",
            "Answer:\n",
            "\n",
            "Focus Punch's accuracy value is the ability to control the movement of the target\n"
          ]
        }
      ],
      "source": [
        "print(generate_answer(\"Based on the context, what is Focus Punch's accuracy value?\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "JlsSuXIdt8gd",
      "metadata": {
        "id": "JlsSuXIdt8gd"
      },
      "outputs": [],
      "source": [
        "!git config --global user.name \"alihuss1017\"\n",
        "!git config --global user.email \"alihuss1017@gmail.com\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git add RAG-setup.py\n",
        "!git commit -m \"[UPDATE] RAG setup\"\n",
        "!git push --force origin RAG-pipeline"
      ],
      "metadata": {
        "id": "Ucx5c-Gu7sGx",
        "outputId": "2aea632f-81e7-42c3-cc5e-6f85c7400d9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Ucx5c-Gu7sGx",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch RAG-pipeline\n",
            "Your branch and 'origin/RAG-pipeline' have diverged,\n",
            "and have 1 and 1 different commits each, respectively.\n",
            "  (use \"git pull\" to merge the remote branch into yours)\n",
            "\n",
            "nothing to commit, working tree clean\n",
            "Enumerating objects: 5, done.\n",
            "Counting objects: 100% (5/5), done.\n",
            "Delta compression using up to 8 threads\n",
            "Compressing objects: 100% (3/3), done.\n",
            "Writing objects: 100% (3/3), 381 bytes | 381.00 KiB/s, done.\n",
            "Total 3 (delta 2), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
            "To https://github.com/alihuss1017/hgss-llm.git\n",
            " + c40d4ed...814ffde RAG-pipeline -> RAG-pipeline (forced update)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wFj85QLi80ge"
      },
      "id": "wFj85QLi80ge",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}